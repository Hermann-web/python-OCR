# -*- coding: utf-8 -*-
"""Copie de reconnaissance_de_nombres.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i4YmIN6zR8L6kj0WOf1auLY1Ef_Z4HxX
"""

!pip install tensorflow

import tensorflow as tf

from tensorflow.keras.datasets import mnist #import d'une biblio de 70.000 images
(xtrain, ytrain), (xtest, ytest) = mnist.load_data() #xtrain est une liste de tableau où chaque tableau est une image

print("xtrain: shape = ", xtrain.shape)
print("xtest: shape = ", xtest.shape)
print("ytrain: shape = ", ytrain.shape)
print("ytest: shape = ", ytest.shape)

"""les images sont de tailles 28*28

On va afficher qq images
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline 
#pour être sur que ce sera importé en ligne 

Liste = [0,1,2,500]
for n in Liste:
  plt.imshow(xtrain[n], cmap='binary')  #la deuxième image #c'esr du noir sur blanc
  plt.show()
  print("le nombre est ", ytrain[n] )

"""Voir les etiquettes """

print(set(ytrain))

"""On fera une normalisation: encodage sur 9 bits: une valeur sera=1 et le reste sera nul"""

from tensorflow.keras.utils import to_categorical

ytrain_encoded = to_categorical(ytrain)
ytest_encoded = to_categorical(ytest)

ytrain[:7], ytrain_encoded[:7]

"""chaque donnée devient une liste de 0 et de 1 seul 1

C'est un probleme de regression lineaire finalement
On aura 3 couches, 128 noeuds dans les deux premières et 10 dans la troixième

On va transformer les tableaux en vecteurs
"""

import numpy as np 
new_shape = xtrain.shape[0], xtrain.shape[1]*xtrain.shape[2]
x_train_reshaped = xtrain.reshape(new_shape)
print("x_train_reshaped.shape = ",x_train_reshaped.shape)

new_shape = xtest.shape[0], xtest.shape[1]*xtest.shape[2]
x_test_reshaped = xtest.reshape(new_shape)
print("x_test_reshaped.shape= ",x_test_reshaped.shape)

"""chaque element est un pixel, une intensite entre 0 et 255"""

#print(x_train_reshaped[0])
max(x_train_reshaped[0])

"""On va normamiser les données: on soustrait la moyenne et on divise par l'ecart-type"""

x_mean_train = x_train_reshaped.mean()
print( "moyenne =",x_mean_train)
x_var_train = x_train_reshaped.std()
print("ecart-type = ", x_var_train)

x_mean_test = x_test_reshaped.mean()
print( "moyenne =",x_mean_test)
x_var_test = x_test_reshaped.std()
print("ecart-type = ", x_var_test)

x_train_norme = (x_train_reshaped - x_mean_train)/x_var_train 
x_test_norme = (x_test_reshaped - x_mean_test)/x_var_test

"""creation du reseau de neurone: 3 couches: 128,128,10"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([ 
    Dense(128,activation="relu", input_shape=(784,)),
    Dense(128,activation="relu"),
    Dense(10,activation="softmax"),
  ])

model.compile(
    optimizer="sgd",
    loss = 'categorical_crossentropy',
    metrics = ['accuracy']
)

"""precision sur le train: le loss est une variance et le accuraccy est l'efficacité"""

model.fit(x_train_norme, ytrain_encoded ,epochs=3  )

"""precision sur le test"""

loss,accuracy =model.evaluate(x_test_norme,ytest_encoded) 
print("variance on test= ",loss)
print("precision on test= ",accuracy)



"""voir les 25 premieres images"""

preds = model.predict(x_test_norme)
print("preds.shape = ", preds.shape) #10000 images test * 10 elms par liste

preds[0] #elemt_i = proba que la premiere image soit = i. Il prends la plus grande valeur ey dit que c'est ça l'image

plt.figure(figsize=(12,12)) #fixer la taille de l'image

start_index = 0

for i in range(25):
  plt.subplot(5,5,i+1)
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  pred = np.argmax(preds[start_index+ i])  #recupere la plus grande probabilite
  gt = ytest[start_index + i] #veritable valeur

  col="g"
  if pred!=gt:
    col='r'
  plt.xlabel("i={} prdit={} realVal={}".format(i,pred,gt),color=col)
  plt.imshow(xtest[start_index+i],cmap="binary")

plt.show()

"""voir quelle etait sa precision"""

plt.plot(preds[8])
plt.show()

plt.plot(preds[5])
plt.show()
plt.plot(preds[8])
plt.show()